{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import *\n",
    "\n",
    "splitter = load_idxsplit()\n",
    "\n",
    "x_train, x_val, x_test = load_x(splitter).values()\n",
    "y_train, y_val, y_test = load_y(splitter).values()\n",
    "\n",
    "diag = load_diagnoses(splitter)\n",
    "left_diag_train, left_diag_val, left_diag_test = diag[\"left\"].values()\n",
    "right_diag_train, right_diag_val, right_diag_test = diag[\"right\"].values()\n",
    "\n",
    "diag_mask = load_diagnosis_masks(splitter)\n",
    "left_diag_mask_train, left_diag_mask_val, left_diag_mask_test = diag_mask[\"left\"].values()\n",
    "right_diag_mask_train, right_diag_mask_val, right_diag_mask_test = diag_mask[\"right\"].values()\n",
    "\n",
    "images = load_images(splitter)\n",
    "left_fundus_images_train, left_fundus_images_val, left_fundus_images_test = images[\"left\"].values()\n",
    "right_fundus_images_train, right_fundus_images_val, right_fundus_images_test = images[\"right\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  135\n"
     ]
    }
   ],
   "source": [
    "sentences = left_diag_train + right_diag_train\n",
    "\n",
    "max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "uniq_words = set()\n",
    "for sentence in sentences:\n",
    "    uniq_words.update(sentence)\n",
    "print(\"Unique words: \", len(uniq_words))\n",
    "\n",
    "from src.embed.vocab import VocabEntry\n",
    "\n",
    "vocab = VocabEntry()\n",
    "for word in uniq_words:\n",
    "  vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# print(\"available device: {}\".format(device))\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.m3care import M3Care\n",
    "\n",
    "model = M3Care(\n",
    "    input_dim = x_train.shape[-1],\n",
    "    hidden_dim = 128,\n",
    "    embed_size = 128,\n",
    "    output_dim = 3,\n",
    "    keep_prob = 0.5,\n",
    "    vocab=vocab,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "RAND_SEED = 42\n",
    "np.random.seed(RAND_SEED)\n",
    "random.seed(RAND_SEED)\n",
    "torch.manual_seed(RAND_SEED)\n",
    "torch.cuda.manual_seed(RAND_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "\n",
    "total_train_loss = list()\n",
    "total_val_loss = list()\n",
    "\n",
    "global_best = 0\n",
    "_global_best = 0\n",
    "\n",
    "history = list()\n",
    "\n",
    "fold_count = 0\n",
    "fold_train_loss = []\n",
    "fold_valid_loss = []\n",
    "\n",
    "best_auc_scores = 0\n",
    "best_ave_auc_micro = 0\n",
    "best_ave_auc_macro = 0\n",
    "best_coverage_error = 0\n",
    "best_label_ranking_loss = 0\n",
    "\n",
    "\n",
    "_best_auc_scores = 0\n",
    "_best_ave_auc_micro = 0\n",
    "_best_ave_auc_macro = 0\n",
    "_best_coverage_error = 0\n",
    "_best_label_ranking_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true, weight=None):\n",
    "    loss = torch.nn.BCEWithLogitsLoss(weight=weight)\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def batch_iter(x, y, left_fundus, right_fundus, left_diag, left_diag_mask, right_diag, right_diag_mask, \\\n",
    "               batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size)  # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size]  # fetch out all the induces\n",
    "\n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], left_fundus[idx], right_fundus[idx], left_diag[idx], \\\n",
    "                             left_diag_mask[idx], right_diag[idx], right_diag_mask[idx]))\n",
    "\n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_left_fundus = [e[2] for e in examples]\n",
    "        batch_right_fundus = [e[3] for e in examples]\n",
    "        batch_left_diag = [e[4] for e in examples]\n",
    "        batch_left_diag_mask = [e[5] for e in examples]\n",
    "        batch_right_diag = [e[6] for e in examples]\n",
    "        batch_right_diag_mask = [e[7] for e in examples]\n",
    "\n",
    "\n",
    "        yield batch_x, batch_y, batch_left_fundus, batch_right_fundus, batch_left_diag, \\\n",
    "        batch_right_diag,  [batch_left_diag_mask, batch_right_diag_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_13112\\1037800883.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  batch_x = torch.tensor(batch_x, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.functional' has no attribute 'max_pool1d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_left_fundus_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_left_fundus_images, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m batch_right_fundus_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_right_fundus_images, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 19\u001b[0m opt, sum_of_diff\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_left_fundus_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_right_fundus_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_left_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_right_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_r_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\src\\m3care.py:97\u001b[0m, in \u001b[0;36mM3Care.forward\u001b[1;34m(self, tabular, left_fundus, right_fundus, left_diag, right_diag, l_r_masks)\u001b[0m\n\u001b[0;32m     93\u001b[0m tabular_mask \u001b[38;5;241m=\u001b[39m length_to_mask(torch\u001b[38;5;241m.\u001b[39mones((tabular_hidden\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mint(\n\u001b[0;32m     94\u001b[0m )\u001b[38;5;241m.\u001b[39msqueeze())\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Natural Language Modality\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m left_diag_contexts, left_diag_lens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNLP_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_diag\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b t h\u001b[39;00m\n\u001b[0;32m     98\u001b[0m right_diag_contexts, right_diag_lens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNLP_model(\n\u001b[0;32m     99\u001b[0m     right_diag)  \u001b[38;5;66;03m# b t h\u001b[39;00m\n\u001b[0;32m    101\u001b[0m left_diag_contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(left_diag_contexts)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\src\\model\\transformer.py:55\u001b[0m, in \u001b[0;36mNatLangTransformer.forward\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Convert list of lists into tensors\u001b[39;00m\n\u001b[0;32m     52\u001b[0m total_src_padded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mto_input_tensor(\n\u001b[0;32m     53\u001b[0m     source, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevicename)   \u001b[38;5;66;03m# Tensor: (src_len, b)\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m enc_hiddens, first_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_src_padded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m enc_hiddens, source_lengths\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\src\\model\\transformer.py:79\u001b[0m, in \u001b[0;36mNatLangTransformer.encode\u001b[1;34m(self, source_padded)\u001b[0m\n\u001b[0;32m     76\u001b[0m source_padded \u001b[38;5;241m=\u001b[39m source_padded\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# b t\u001b[39;00m\n\u001b[0;32m     77\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m (source_padded \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# b t 1\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_padded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m enc_hiddens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(X, src_mask)  \u001b[38;5;66;03m# b t h\u001b[39;00m\n\u001b[0;32m     82\u001b[0m first_hidden \u001b[38;5;241m=\u001b[39m enc_hiddens[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\src\\embed\\char_embed.py:65\u001b[0m, in \u001b[0;36mCharacterEmbedding.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# (b*s x o)\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool1d\u001b[49m(x, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# (b x s x o)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.functional' has no attribute 'max_pool1d'"
     ]
    }
   ],
   "source": [
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model.train()\n",
    "    for step, (batch_x, batch_y, batch_left_fundus_images, batch_right_fundus_images, batch_left_diag, \\\n",
    "    batch_right_diag, l_r_masks) in enumerate(\n",
    "            batch_iter(x_train, y_train, left_fundus_images_train, right_fundus_images_train, left_diag_train,\n",
    "                        left_diag_mask_train, right_diag_train, right_diag_mask_train, \\\n",
    "                       batch_size, shuffle=True)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_x = torch.tensor(batch_x, dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device).squeeze(-1)\n",
    "\n",
    "        batch_left_fundus_images = torch.tensor(batch_left_fundus_images, dtype=torch.float32).to(device)\n",
    "        batch_right_fundus_images = torch.tensor(batch_right_fundus_images, dtype=torch.float32).to(device)\n",
    "\n",
    "        opt, sum_of_diff= model(batch_x, batch_left_fundus_images, batch_right_fundus_images, \\\n",
    "                    batch_left_diag, batch_right_diag, l_r_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((7,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = x[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b], dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
