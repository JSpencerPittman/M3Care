{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9e17eb-b077-4174-b856-6fbe90c2104b",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90c1883-09fc-4065-bdb9-c20de88e6856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b74b17-62f8-4217-8cd4-bba4522e9033",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188d4018-b7da-4fab-9bab-ad2e84900806",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIMICDataset(Dataset):\n",
    "    def __init__(self, processed_dir: str, train: bool):\n",
    "        self.processed_dir = processed_dir\n",
    "\n",
    "        data_path = os.path.join(processed_dir, ('train/' if train else 'test/'))\n",
    "        index_path = os.path.join(processed_dir, f\"{'train' if train else 'test'}_idxs.npy\")\n",
    "\n",
    "        try:\n",
    "            self.indexes = np.load(index_path)\n",
    "            self.vocab = Vocab.from_json(os.path.join(processed_dir, 'vocab.json')) \n",
    "            self.notes_ts_path = os.path.join(data_path, 'notes_ts.h5')\n",
    "            if not os.path.exists(self.notes_ts_path):\n",
    "                raise FileNotFoundError()\n",
    "        except FileNotFoundError as e:\n",
    "            print(\"Make sure data has been processed: \", e)\n",
    "            return\n",
    "        \n",
    "        with h5py.File(self.notes_ts_path, 'r') as f:\n",
    "            self.nts_ids = set([int(k.split('_')[-1]) for k in list(f.keys())])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "\n",
    "    def __getitem__(self, item_idx):\n",
    "        pat_id = self.indexes[item_idx]\n",
    "\n",
    "    def __getitem__(self, item_idx):\n",
    "        pat_id = self.indexes[item_idx]\n",
    "\n",
    "        if type(pat_id) != np.ndarray:\n",
    "            return self._getpatient(pat_id)\n",
    "        else:\n",
    "            return self._getpatients(pat_id)\n",
    "\n",
    "    def _getpatient(self, pat_id):\n",
    "        nts, missing = None, None\n",
    "        \n",
    "        if pat_id not in self.nts_ids:\n",
    "            nts = (np.empty(0), np.empty(0), np.empty(0))\n",
    "            missing = True\n",
    "        else:\n",
    "            with h5py.File(self.notes_ts_path, 'r') as f:\n",
    "                nts = self._format_notes_ts_group(f[f'pat_id_{pat_id}'])\n",
    "                missing = False\n",
    "\n",
    "        return nts, missing\n",
    "    \n",
    "    def _getpatients(self, pat_ids):\n",
    "        nts, missing = [], []\n",
    "        \n",
    "        match_ids = [pat_id for pat_id in pat_ids if pat_id in self.nts_ids]\n",
    "\n",
    "        with h5py.File(self.notes_ts_path, 'r') as f:\n",
    "            for pat_id in pat_ids:\n",
    "                if pat_id in match_ids:\n",
    "                    nts.append(self._format_notes_ts_group(f[f'pat_id_{pat_id}']))\n",
    "                    missing.append(True)\n",
    "                else:\n",
    "                    missing.append(False)\n",
    "\n",
    "        return nts, missing\n",
    "\n",
    "    @staticmethod\n",
    "    def _format_notes_ts_group(nts_group):\n",
    "        group_size = len(nts_group)\n",
    "        times, cats, notes = [0]*group_size, [0]*group_size, [0]*group_size\n",
    "        for d in nts_group.keys():\n",
    "            _, gidx, _, time, _, cat = d.split('_')\n",
    "            gidx, time, cat = int(gidx), int(time), np.array([int(c) for c in cat])\n",
    "            times[gidx] = time\n",
    "            cats[gidx] = cat\n",
    "            notes[gidx] = nts_group[d][:]\n",
    "\n",
    "        times, cats = np.array(times), np.array(cats)\n",
    "        \n",
    "        max_note_len = max([len(note) for note in notes])\n",
    "        notes = np.array([np.pad(note, (0, max_note_len-len(note))) for note in notes])\n",
    "\n",
    "        return times, cats, notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4fa4a76-0681-46c1-a1d7-468dc3659029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MIMICDataset('../data/processed/', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d63f7-3dda-4e43-a518-0125ffa20e24",
   "metadata": {},
   "source": [
    "## Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa939bc5-ae72-47c3-a21e-d316026b01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOKEN = '[SEP]'\n",
    "\n",
    "class Vocab(object):\n",
    "    def __init__(self):\n",
    "        self.tok2id = {}\n",
    "        self.id2tok = {}\n",
    "        self.tok2cnt = {}\n",
    "        self.cnt = 1\n",
    "\n",
    "    def add_token(self, token: str):\n",
    "        if token not in self.tok2id:\n",
    "            self.tok2id[token] = self.cnt\n",
    "            self.id2tok[self.cnt] = token\n",
    "            self.tok2cnt[token] = 1\n",
    "            self.cnt += 1\n",
    "        else:\n",
    "            self.tok2cnt[token] += 1\n",
    "\n",
    "    def top_tokens(self, top: int):\n",
    "        return set([tok for _, tok in sorted(list({v:k for k,v in self.tok2cnt.items()}.items()), reverse=True)[:top]])\n",
    "\n",
    "    def to_json(self, path: str):\n",
    "        vocab_data = {\n",
    "            'tok2id': self.tok2id,\n",
    "            'id2tok': self.id2tok,\n",
    "            'tok2cnt': self.tok2cnt,\n",
    "            'cnt': self.cnt\n",
    "        }\n",
    "\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(vocab_data, f, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path: str):\n",
    "        with open(path, 'r') as f:\n",
    "            vocab_data = json.load(f)\n",
    "\n",
    "        v = Vocab()\n",
    "        v.tok2id = {k: int(v) for k,v in vocab_data['tok2id'].items()}\n",
    "        v.id2tok = {int(k): v for k,v in vocab_data['id2tok'].items()}\n",
    "        v.tok2cnt = {k: int(v) for k,v in vocab_data['tok2cnt'].items()}\n",
    "        v.cnt = vocab_data['cnt']\n",
    "\n",
    "        return v\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9667db1-9018-4878-b1f3-c36f4e9bc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, vocab, vocab_size, embed_dim, d_model):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        \n",
    "        # Create idx -> embed_idx mapping\n",
    "        top_words = vocab.top_tokens(vocab_size+1)\n",
    "        top_words.remove(SEP_TOKEN)\n",
    "        self.emb_idx_map = {vocab.tok2id[tok]: idx for idx, tok in enumerate(top_words, start=1)}\n",
    "        self.sep_tok_id = vocab.tok2id[SEP_TOKEN]\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # SEP[0] VOCAB[1,V] UNKNOWN[V+1] PADDING[V+2]  \n",
    "        self.embedder = nn.Embedding(vocab_size+3, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, d_model)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = torch.LongTensor([[self.embed_idx(idx) for idx in seq] for seq in x]).to(self.embedder.weight.device)\n",
    "        x = self.embedder(x)\n",
    "        return F.relu(self.linear(x))\n",
    "\n",
    "    def embed_idx(self, idx):\n",
    "        if idx == self.sep_tok_id:\n",
    "            return 0\n",
    "        elif idx in self.emb_idx_map:\n",
    "            return self.emb_idx_map[idx]\n",
    "        elif idx == 0:\n",
    "            return self.vocab_size+2\n",
    "        else:\n",
    "            return self.vocab_size+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465b8eb-ba1d-45c0-83c2-afc65545f7a4",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "722b80d1-94b9-477d-bb4a-b3938930d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee89fd-b801-498e-a2ae-76cd5c881fa3",
   "metadata": {},
   "source": [
    "## Time2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4641c1a6-5f51-4272-9480-ba7b7d004f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(nn.Module):\n",
    "    def __init__(self, max_len=5000):\n",
    "        super(Time2Vec, self).__init__()\n",
    "        \n",
    "        self.omega = nn.Parameter(torch.randn(max_len))\n",
    "        self.phi = nn.Parameter(torch.randn(max_len))\n",
    "\n",
    "    def forward(self, tau):\n",
    "        seq_len = tau.size(0)\n",
    "        zero_start = bool(tau[0] == 0)\n",
    "        tau = (tau*self.omega[:seq_len]) + self.phi[:seq_len]\n",
    "        tau[zero_start:] = torch.sin(tau[zero_start:])\n",
    "        return tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5dcf9-b1f9-4f20-b01a-4d2076bca316",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acff6c-7da2-4386-acd8-1575dbb794f8",
   "metadata": {},
   "source": [
    "determine device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3beb2adb-a614-4e18-8e65-43d39d8a3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b8015-55aa-422b-9940-b820f0430088",
   "metadata": {},
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f7fa07-6afe-4490-b862-5ffd4e6e1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General \n",
    "DROPRATE = 0.3\n",
    "\n",
    "# Embedder\n",
    "EMBD_DIM = 10\n",
    "\n",
    "# Transformer\n",
    "TRAN_DMODEL = 512\n",
    "TRAN_NHEAD = 8\n",
    "TRAN_DFF = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7388f1-3d18-4f96-8b4d-32ef0d5f2082",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93df2a73-f401-4aa4-8b3b-1a2d097a3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed = WordEmbedder(train_ds.vocab, 10000, EMBD_DIM, TRAN_DMODEL).to(device)\n",
    "\n",
    "pos_encode = PositionalEncoding(TRAN_DMODEL, DROPRATE).to(device)\n",
    "\n",
    "enc_layer = nn.TransformerEncoderLayer(TRAN_DMODEL, TRAN_NHEAD, TRAN_DFF, DROPRATE, batch_first=True).to(device)\n",
    "\n",
    "time_2_vec = Time2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82279be5-0664-4ac0-9763-badfc5c88fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrregularTimeNLP(nn.Module):\n",
    "    def __init__(self, vocab, embed_dim, model_dim, tran_heads, tran_dff, vocab_size=10000, dropout=0.3):\n",
    "        super(IrregularTimeNLP, self).__init__()\n",
    "\n",
    "        self.word_embed = WordEmbedder(vocab, vocab_size, embed_dim, model_dim)\n",
    "        self.pos_encode = PositionalEncoding(model_dim, dropout)\n",
    "        self.enc_layer = nn.TransformerEncoderLayer(model_dim, tran_heads, tran_dff, dropout, batch_first=True)\n",
    "\n",
    "        self.time2vec = Time2Vec()\n",
    "\n",
    "    def forward(self, times, cats, notes):\n",
    "        notes = self.word_embed(notes)\n",
    "        notes = self.pos_encode(notes)\n",
    "        notes = self.enc_layer(notes)\n",
    "        notes = notes.mean(dim=1)\n",
    "\n",
    "        times = self.time2vec(times)\n",
    "\n",
    "        return torch.cat([times.unsqueeze(1),cats,notes], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f89b3e40-b6c7-4872-a203-ed42ec465345",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrregularTimeNLP(train_ds.vocab, 10, 512, 8, 2048).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bef75e07-0976-4a44-93a6-08b606dd88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_ds[0][0]\n",
    "sample_time = torch.tensor(sample[0]).to(device)\n",
    "sample_cat = torch.tensor(sample[1]).to(device)\n",
    "sample_note = torch.tensor(sample[2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b97ebb92-82ae-49c0-86f0-08006e02da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(sample_time, sample_cat, sample_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e54d2366-113e-4472-b2c3-35591258616c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   3,   5,  13,  14,  15,  24,  26,  27,  36,  37,  38,  50,\n",
       "         50,  50,  50,  51,  62,  64,  65,  74,  76,  86,  86,  86,  86,\n",
       "         91,  97,  99, 110, 110, 110, 110, 110, 110, 110, 110, 110, 119,\n",
       "        121, 136]),\n",
       " array([[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]]),\n",
       " array([[ 552,    4,  199, ...,    0,    0,    0],\n",
       "        [  85,  831,    4, ...,    0,    0,    0],\n",
       "        [3497,    1, 1041, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 525,  957,    4, ...,    0,    0,    0],\n",
       "        [1048, 8266, 1041, ...,    0,    0,    0],\n",
       "        [3497, 1048, 8266, ...,    0,    0,    0]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b319f-3861-4d23-b065-5d1a1302faae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic3",
   "language": "python",
   "name": "mimic3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
