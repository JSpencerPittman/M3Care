{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torcheval.metrics import BinaryAUROC, BinaryAUPRC\n",
    "\n",
    "os.chdir('../..')\n",
    "from src.raindrop.raindrop import Raindrop\n",
    "from src.raindrop.classifier import RaindropClassifier\n",
    "from src.util.grad_track import GradientTracker, GradientFlowAnalyzer, pretty_flow\n",
    "from src.p19.utils import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: model_20241018_092728_16\n"
     ]
    }
   ],
   "source": [
    "def load_latest_model(models_dir: Path = Path('./models')) -> nn.Module:\n",
    "    assert models_dir.exists()\n",
    "\n",
    "    def model_name_key(name: str):\n",
    "        return math.prod([int(v) for v in name.split('_')[1:]])\n",
    "\n",
    "    recent_model_name = sorted(next(models_dir.walk())[2],\n",
    "                               key=model_name_key)[-1]\n",
    "    \n",
    "    print(\"Loading model:\", recent_model_name)\n",
    "        \n",
    "    state_dict = torch.load(models_dir / recent_model_name,\n",
    "                            weights_only=True)\n",
    "    \n",
    "    raindrop = Raindrop(num_sensors=34,\n",
    "                 obs_dim=1,\n",
    "                 obs_embed_dim=4,\n",
    "                 pe_emb_dim=16,\n",
    "                 timesteps=60,\n",
    "                 out_dim=128,\n",
    "                 num_heads=1,\n",
    "                 num_layers=2,\n",
    "                 inter_sensor_attn_dim=16,\n",
    "                 temporal_attn_dim=16,\n",
    "                 prune_rate=0.5,\n",
    "                 device=device)\n",
    "\n",
    "    rd_cls = RaindropClassifier(raindrop,\n",
    "                                static_dim=6,\n",
    "                                static_proj_dim=34,\n",
    "                                cls_hidden_dim=128,\n",
    "                                classes=2).to(device)\n",
    "    \n",
    "    rd_cls.load_state_dict(state_dict)\n",
    "    rd_cls.eval()\n",
    "\n",
    "    return rd_cls\n",
    "\n",
    "rd_cls = load_latest_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataloaders_from_splits(\n",
    "        data_path: Path = Path('./data/p19/processed_data'),\n",
    "        splits_dir: Path = Path('./data/p19/splits')) -> nn.Module:\n",
    "    assert splits_dir.exists()\n",
    "\n",
    "    ds_names = ['train', 'val', 'test']\n",
    "\n",
    "    ts_inputs, static_inputs, times, lengths, labels = \\\n",
    "        load_p19_data(data_path, device)\n",
    "\n",
    "    dataloaders: dict[str, DataLoader] = {}\n",
    "    for ds_name in ds_names:\n",
    "        idxs = np.load(splits_dir / f\"{ds_name}_idxs.npy\")\n",
    "        dataset = P19Dataset(ts_inputs[idxs],\n",
    "                             times[idxs],\n",
    "                             lengths[idxs],\n",
    "                             static_inputs[idxs],\n",
    "                             labels[idxs],\n",
    "                             device)\n",
    "        dataloaders[ds_name] = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "dls = load_dataloaders_from_splits()\n",
    "train_dl, val_dl, test_dl = dls['train'], dls['val'], dls['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dl: DataLoader):\n",
    "    predictions, truth = None, None\n",
    "    with torch.no_grad():\n",
    "        for ts_inp, times, mask, static_inp, labels in dl:\n",
    "            pred = rd_cls(ts_inp, times, mask, static_inp)[0]\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "                truth = labels\n",
    "            else:\n",
    "                predictions = torch.cat([predictions, pred])\n",
    "                truth = torch.cat([truth, labels])\n",
    "\n",
    "    return truth, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_auroc_metric = BinaryAUROC()\n",
    "bin_auprc_metric = BinaryAUPRC()\n",
    "\n",
    "def au_scores(truth, predictions):\n",
    "    predictions = predictions.argmax(dim=-1)\n",
    "\n",
    "    bin_auroc_metric.update(predictions, truth)\n",
    "    bin_auprc_metric.update(predictions, truth)\n",
    "\n",
    "    print(f\"AUROC: {bin_auroc_metric.compute()}\")\n",
    "    print(f\"AUPRC: {bin_auprc_metric.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(truth, predictions):\n",
    "    truth = truth.bool()\n",
    "    predictions = predictions.argmax(dim=-1).bool()\n",
    "    tp = (truth * predictions).sum().item()\n",
    "    fp = (~truth * predictions).sum().item()\n",
    "    fn = (truth * ~predictions).sum().item()\n",
    "    tn = (~truth * ~predictions).sum().item()\n",
    "\n",
    "    print(f\"Confusion Matrix\\n{tp:5}|{fn:5}\\n{fp:5}|{tn:5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation\n",
      "AUROC: 0.6151315789473685\n",
      "AUPRC: 0.26041004061698914\n",
      "Confusion Matrix\n",
      "   35|  117\n",
      "    0| 3729\n"
     ]
    }
   ],
   "source": [
    "test_truth, test_pred = predict(test_dl)\n",
    "print(\"Test Evaluation\")\n",
    "au_scores(test_truth, test_pred)\n",
    "confusion_matrix(test_truth, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Evaluation\n",
      "AUROC: 0.6253822629969419\n",
      "AUPRC: 0.2823326289653778\n",
      "Confusion Matrix\n",
      "   47|  128\n",
      "    0| 3705\n"
     ]
    }
   ],
   "source": [
    "val_truth, val_pred = predict(val_dl)\n",
    "print(\"Validation Evaluation\")\n",
    "au_scores(val_truth, val_pred)\n",
    "confusion_matrix(val_truth, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation\n",
      "AUROC: 0.6245118470363228\n",
      "AUPRC: 0.2793201506137848\n",
      "Confusion Matrix\n",
      "  323|  976\n",
      "    2|29741\n"
     ]
    }
   ],
   "source": [
    "train_truth, train_pred = predict(train_dl)\n",
    "print(\"Train Evaluation\")\n",
    "au_scores(train_truth, train_pred)\n",
    "confusion_matrix(train_truth, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
