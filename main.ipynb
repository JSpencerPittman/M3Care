{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load import *\n",
    "\n",
    "splitter = load_idxsplit()\n",
    "\n",
    "x_train, x_val, x_test = load_x(splitter).values()\n",
    "y_train, y_val, y_test = load_y(splitter).values()\n",
    "\n",
    "diag = load_diagnoses(splitter)\n",
    "left_diag_train, left_diag_val, left_diag_test = diag[\"left\"].values()\n",
    "right_diag_train, right_diag_val, right_diag_test = diag[\"right\"].values()\n",
    "\n",
    "diag_mask = load_diagnosis_masks(splitter)\n",
    "left_diag_mask_train, left_diag_mask_val, left_diag_mask_test = diag_mask[\"left\"].values()\n",
    "right_diag_mask_train, right_diag_mask_val, right_diag_mask_test = diag_mask[\"right\"].values()\n",
    "\n",
    "images = load_images(splitter)\n",
    "left_fundus_images_train, left_fundus_images_val, left_fundus_images_test = images[\"left\"].values()\n",
    "right_fundus_images_train, right_fundus_images_val, right_fundus_images_test = images[\"right\"].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:  135\n"
     ]
    }
   ],
   "source": [
    "sentences = left_diag_train + right_diag_train\n",
    "\n",
    "max_len = max([len(sentence) for sentence in sentences])\n",
    "\n",
    "uniq_words = set()\n",
    "for sentence in sentences:\n",
    "    uniq_words.update(sentence)\n",
    "print(\"Unique words: \", len(uniq_words))\n",
    "\n",
    "from m3care.cs224n.vocab import VocabEntry\n",
    "\n",
    "vocab = VocabEntry()\n",
    "for word in uniq_words:\n",
    "  vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# print(\"available device: {}\".format(device))\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m3care.model import M3Care\n",
    "\n",
    "model = M3Care(\n",
    "    input_dim = x_train.shape[-1],\n",
    "    hidden_dim = 128,\n",
    "    embed_size = 128,\n",
    "    output_dim = 3,\n",
    "    keep_prob = 0.5,\n",
    "    vocab=vocab,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "RAND_SEED = 42\n",
    "np.random.seed(RAND_SEED)\n",
    "random.seed(RAND_SEED)\n",
    "torch.manual_seed(RAND_SEED)\n",
    "torch.cuda.manual_seed(RAND_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "\n",
    "total_train_loss = list()\n",
    "total_val_loss = list()\n",
    "\n",
    "global_best = 0\n",
    "_global_best = 0\n",
    "\n",
    "history = list()\n",
    "\n",
    "fold_count = 0\n",
    "fold_train_loss = []\n",
    "fold_valid_loss = []\n",
    "\n",
    "best_auc_scores = 0\n",
    "best_ave_auc_micro = 0\n",
    "best_ave_auc_macro = 0\n",
    "best_coverage_error = 0\n",
    "best_label_ranking_loss = 0\n",
    "\n",
    "\n",
    "_best_auc_scores = 0\n",
    "_best_ave_auc_micro = 0\n",
    "_best_ave_auc_macro = 0\n",
    "_best_coverage_error = 0\n",
    "_best_label_ranking_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true, weight=None):\n",
    "    loss = torch.nn.BCEWithLogitsLoss(weight=weight)\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def batch_iter(x, y, left_fundus, right_fundus, left_diag, left_diag_mask, right_diag, right_diag_mask, \\\n",
    "               batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size)  # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size]  # fetch out all the induces\n",
    "\n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], left_fundus[idx], right_fundus[idx], left_diag[idx], \\\n",
    "                             left_diag_mask[idx], right_diag[idx], right_diag_mask[idx]))\n",
    "\n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_left_fundus = [e[2] for e in examples]\n",
    "        batch_right_fundus = [e[3] for e in examples]\n",
    "        batch_left_diag = [e[4] for e in examples]\n",
    "        batch_left_diag_mask = [e[5] for e in examples]\n",
    "        batch_right_diag = [e[6] for e in examples]\n",
    "        batch_right_diag_mask = [e[7] for e in examples]\n",
    "\n",
    "\n",
    "        yield batch_x, batch_y, batch_left_fundus, batch_right_fundus, batch_left_diag, \\\n",
    "        batch_right_diag,  [batch_left_diag_mask, batch_right_diag_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp\\ipykernel_5180\\1037800883.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  batch_x = torch.tensor(batch_x, dtype=torch.float32).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODE#1:  torch.Size([10, 512])\n",
      "ENCODE#2:  torch.Size([512, 10, 128])\n",
      "ENCODE#3:  torch.Size([512, 1, 10])\n",
      "Layer 0: EncoderLayer(\n",
      "  (self_attn): MultiHeadedAttention(\n",
      "    (linears): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (feed_forward): PositionwiseFeedForward(\n",
      "    (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (sublayer): ModuleList(\n",
      "    (0-1): 2 x SublayerConnection(\n",
      "      (norm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 10])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 8, 10, 16]) K torch.Size([512, 8, 10, 16]) V torch.Size([512, 8, 10, 16])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "XOUT: torch.Size([512, 10, 128])\n",
      "ENCODE#4:  torch.Size([512, 10, 128])\n",
      "TRANSFORMEROUTPUT: {enc_hiddens.shape}\n",
      "ENCODE#1:  torch.Size([12, 512])\n",
      "ENCODE#2:  torch.Size([512, 12, 128])\n",
      "ENCODE#3:  torch.Size([512, 1, 12])\n",
      "Layer 0: EncoderLayer(\n",
      "  (self_attn): MultiHeadedAttention(\n",
      "    (linears): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (feed_forward): PositionwiseFeedForward(\n",
      "    (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (sublayer): ModuleList(\n",
      "    (0-1): 2 x SublayerConnection(\n",
      "      (norm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 12])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 8, 12, 16]) K torch.Size([512, 8, 12, 16]) V torch.Size([512, 8, 12, 16])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "XOUT: torch.Size([512, 12, 128])\n",
      "ENCODE#4:  torch.Size([512, 12, 128])\n",
      "TRANSFORMEROUTPUT: {enc_hiddens.shape}\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 25])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 4, 25, 32]) K torch.Size([512, 4, 25, 32]) V torch.Size([512, 4, 25, 32])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 25])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 1, 25, 128]) K torch.Size([512, 1, 25, 128]) V torch.Size([512, 1, 25, 128])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "ENCODE#1:  torch.Size([10, 512])\n",
      "ENCODE#2:  torch.Size([512, 10, 128])\n",
      "ENCODE#3:  torch.Size([512, 1, 10])\n",
      "Layer 0: EncoderLayer(\n",
      "  (self_attn): MultiHeadedAttention(\n",
      "    (linears): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (feed_forward): PositionwiseFeedForward(\n",
      "    (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (sublayer): ModuleList(\n",
      "    (0-1): 2 x SublayerConnection(\n",
      "      (norm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 10])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 8, 10, 16]) K torch.Size([512, 8, 10, 16]) V torch.Size([512, 8, 10, 16])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "XOUT: torch.Size([512, 10, 128])\n",
      "ENCODE#4:  torch.Size([512, 10, 128])\n",
      "TRANSFORMEROUTPUT: {enc_hiddens.shape}\n",
      "ENCODE#1:  torch.Size([12, 512])\n",
      "ENCODE#2:  torch.Size([512, 12, 128])\n",
      "ENCODE#3:  torch.Size([512, 1, 12])\n",
      "Layer 0: EncoderLayer(\n",
      "  (self_attn): MultiHeadedAttention(\n",
      "    (linears): ModuleList(\n",
      "      (0-3): 4 x Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (feed_forward): PositionwiseFeedForward(\n",
      "    (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (sublayer): ModuleList(\n",
      "    (0-1): 2 x SublayerConnection(\n",
      "      (norm): LayerNorm()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "MHA STARTED\n",
      "NEWMASKSIZE:  torch.Size([512, 1, 1, 12])\n",
      "Q, K, V found\n",
      "Q torch.Size([512, 8, 12, 16]) K torch.Size([512, 8, 12, 16]) V torch.Size([512, 8, 12, 16])\n",
      "PAID ATTENTION\n",
      "CONCATTING\n",
      "XOUT: torch.Size([512, 12, 128])\n",
      "ENCODE#4:  torch.Size([512, 12, 128])\n",
      "TRANSFORMEROUTPUT: {enc_hiddens.shape}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_left_fundus_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_left_fundus_images, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m batch_right_fundus_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_right_fundus_images, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 19\u001b[0m opt, sum_of_diff\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_left_fundus_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_right_fundus_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_left_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_right_diag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_r_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\m3care\\model.py:106\u001b[0m, in \u001b[0;36mM3Care.forward\u001b[1;34m(self, input, left_fundus, right_fundus, left_diag, right_diag, l_r_masks)\u001b[0m\n\u001b[0;32m    103\u001b[0m right_diag_mask \u001b[38;5;241m=\u001b[39m length_to_mask(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(right_diag_lens)))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Image Data\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m left_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres2hidden1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_fundus\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    107\u001b[0m left_f_mask \u001b[38;5;241m=\u001b[39m length_to_mask(torch\u001b[38;5;241m.\u001b[39mones((values_hidden\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39msqueeze())\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m    109\u001b[0m right_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres2hidden1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet18(right_fundus)))\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for each_epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "    counter_batch = 0\n",
    "    model.train()\n",
    "    for step, (batch_x, batch_y, batch_left_fundus_images, batch_right_fundus_images, batch_left_diag, \\\n",
    "    batch_right_diag, l_r_masks) in enumerate(\n",
    "            batch_iter(x_train, y_train, left_fundus_images_train, right_fundus_images_train, left_diag_train,\n",
    "                        left_diag_mask_train, right_diag_train, right_diag_mask_train, \\\n",
    "                       batch_size, shuffle=True)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_x = torch.tensor(batch_x, dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device).squeeze(-1)\n",
    "\n",
    "        batch_left_fundus_images = torch.tensor(batch_left_fundus_images, dtype=torch.float32).to(device)\n",
    "        batch_right_fundus_images = torch.tensor(batch_right_fundus_images, dtype=torch.float32).to(device)\n",
    "\n",
    "        opt, sum_of_diff= model(batch_x, batch_left_fundus_images, batch_right_fundus_images, \\\n",
    "                    batch_left_diag, batch_right_diag, l_r_masks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
