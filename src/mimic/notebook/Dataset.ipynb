{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "70806f9e-5df9-4a69-97f9-d3525c606779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SEP_TOKEN = '[SEP]'\n",
    "\n",
    "\n",
    "class Vocab(object):\n",
    "    def __init__(self):\n",
    "        self.tok2id = {}\n",
    "        self.id2tok = {}\n",
    "        self.tok2cnt = {}\n",
    "        self.cnt = 1\n",
    "\n",
    "    def add_token(self, token: str):\n",
    "        if token not in self.tok2id:\n",
    "            self.tok2id[token] = self.cnt\n",
    "            self.id2tok[self.cnt] = token\n",
    "            self.tok2cnt[token] = 1\n",
    "            self.cnt += 1\n",
    "        else:\n",
    "            self.tok2cnt[token] += 1\n",
    "\n",
    "    def top_tokens(self, top: int):\n",
    "        return set([tok for _, tok in sorted(list({v: k for k, v in self.tok2cnt.items()}.items()), reverse=True)[:top]])\n",
    "\n",
    "    def to_json(self, path: str):\n",
    "        vocab_data = {\n",
    "            'tok2id': self.tok2id,\n",
    "            'id2tok': self.id2tok,\n",
    "            'tok2cnt': self.tok2cnt,\n",
    "            'cnt': self.cnt\n",
    "        }\n",
    "\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(vocab_data, f, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, path: str):\n",
    "        with open(path, 'r') as f:\n",
    "            vocab_data = json.load(f)\n",
    "\n",
    "        v = Vocab()\n",
    "        v.tok2id = {k: int(v) for k, v in vocab_data['tok2id'].items()}\n",
    "        v.id2tok = {int(k): v for k, v in vocab_data['id2tok'].items()}\n",
    "        v.tok2cnt = {k: int(v) for k, v in vocab_data['tok2cnt'].items()}\n",
    "        v.cnt = vocab_data['cnt']\n",
    "\n",
    "        return v\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "569f9a30-d932-4adc-bfe2-ee669caa21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "processed_dir = '../data/processed/'\n",
    "data_path = os.path.join(processed_dir, 'train')\n",
    "index_path = index_path = os.path.join(processed_dir, \"train_idxs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "3395127b-f461-4c51-a094-17daa600d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "indexes = np.load(index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "c043aaef-9637-44f3-be6f-ce1f776b99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.from_json(\n",
    "    os.path.join(processed_dir, 'vocab.json'))\n",
    "notes_static_path = os.path.join(data_path, 'notes_static.h5')\n",
    "notes_ts_path = os.path.join(data_path, 'notes_ts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "26906488-48d1-47c7-bdff-0a0f0e3b66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(notes_static_path, 'r') as f:\n",
    "        nst_ids = set([int(k.split('_')[-1]) for k in list(f.keys())])\n",
    "with h5py.File(notes_ts_path, 'r') as f:\n",
    "        nts_ids = set([int(k.split('_')[-1]) for k in list(f.keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63afed52-7f96-4843-abd0-80e10e942bba",
   "metadata": {},
   "source": [
    "### Sample Get (Single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "bf0ec728-a593-4fee-82ed-a7b8caaaaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_idx = np.arange(100)\n",
    "# item_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "dca83e78-cffe-486c-8cd1-85bdfc3cd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_id = indexes[item_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "142bfe28-19c5-4325-8a42-9756eb8f06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESERIES_DIM = 150\n",
    "NOTES_TIME_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "51fa89b5-1ec9-477a-8f7d-b87738a27f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(notes_ts_path, 'r') as f:\n",
    "    nts = f[f'pat_id_{pat_id}']\n",
    "    nts = _format_notes_ts_group(nts)\n",
    "    notes, mask = nts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "1a73a5b7-4462-49c9-8222-f672dc72d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 330)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "bc682b8c-af2d-4ad4-b4f5-5e87ccd157cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nst, nts, nst_msk, nts_msk = getpatients_notes(pat_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "cc174728-1420-4378-bd38-0821c5e319e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1) (4, 128, 500) (4,) (4, 128)\n"
     ]
    }
   ],
   "source": [
    "print(nst.shape,nts.shape,nst_msk.shape,nts_msk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "c60b5038-05ff-464e-aa30-73b51bbe5a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1299) (100, 128, 4799) (100,) (100, 128)\n"
     ]
    }
   ],
   "source": [
    "print(nst.shape,nts.shape,nst_msk.shape,nts_msk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62e7d7-8320-4a4c-8d3e-d9e9bf488993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e23c695b-9bcc-4d62-91de-c9d0c7057a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpatients_notes(pat_ids):\n",
    "    match_nst = set([pat_id for pat_id in pat_ids if pat_id in nst_ids])\n",
    "    nst, nst_msk = [], np.zeros(len(pat_ids))\n",
    "    with h5py.File(notes_static_path, 'r') as f:\n",
    "        for pidx, pid in enumerate(pat_ids):\n",
    "            if pid in match_nst:\n",
    "                nst.append(f[f'pat_id_{pid}'][:])\n",
    "                nst_msk[pidx] = 1\n",
    "                \n",
    "    if len(match_nst):\n",
    "        nst = padded_stack(nst)\n",
    "        nst = pad_missing(nst, nst_msk)\n",
    "    else:\n",
    "        nst = np.zeros((len(pat_ids),1))\n",
    "\n",
    "    match_nts = set([pat_id for pat_id in pat_ids if pat_id in nts_ids])\n",
    "    nts, nts_msk = [], np.zeros((len(pat_ids), NOTES_TIME_DIM))\n",
    "    with h5py.File(notes_ts_path, 'r') as f:\n",
    "        for pidx, pid in enumerate(pat_ids):\n",
    "            if pid in match_nts:\n",
    "                gnotes, gmask = _format_notes_ts_group(f[f'pat_id_{pid}'])\n",
    "                nts.append(gnotes)\n",
    "                nts_msk[pidx] = gmask\n",
    "                \n",
    "    if len(match_nts):\n",
    "        nts = padded_stack(nts)\n",
    "        nts = pad_missing(nts, nts_msk.sum(axis=1)>0)\n",
    "    else:\n",
    "        nts = np.zeros((len(pat_ids),NOTES_TIME_DIM,1))\n",
    "   \n",
    "    return nst, nts, nst_msk, nts_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "cb6b4e41-7123-43ca-848b-d94f00e825e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getpatients_notes(self, pat_ids):\n",
    "        nst, nts = [], []\n",
    "        missing = []\n",
    "\n",
    "        missing_st = []\n",
    "        match_ids = set(\n",
    "            [pat_id for pat_id in pat_ids if pat_id in self.nst_ids])\n",
    "        with h5py.File(self.notes_static_path, 'r') as f:\n",
    "            for pat_id in pat_ids:\n",
    "                if pat_id in match_ids:\n",
    "                    nst.append(f[f'row_{pat_id}'][:])\n",
    "                    missing_st.append(False)\n",
    "                else:\n",
    "                    missing_st.append(True)\n",
    "\n",
    "        missing_ts = []\n",
    "        match_ids = set(\n",
    "            [pat_id for pat_id in pat_ids if pat_id in self.nts_ids])\n",
    "        with h5py.File(self.notes_ts_path, 'r') as f:\n",
    "            for pat_id in pat_ids:\n",
    "                if pat_id in match_ids:\n",
    "                    nts.append(self._format_notes_ts_group(\n",
    "                        f[f'pat_id_{pat_id}']))\n",
    "                    missing_ts.append(False)\n",
    "                else:\n",
    "                    missing_ts.append(True)\n",
    "\n",
    "        nst = self._format_notes_static(nst)\n",
    "        missing = np.array(list(zip(missing_st, missing_ts)))\n",
    "\n",
    "        return nst, nts, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "82520c3b-240f-4ad8-b540-9c7b419d33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_notes_ts_group(nts_group):\n",
    "        group_size = len(nts_group)\n",
    "        times, notes = [0]*group_size, [0]*group_size\n",
    "        for d in nts_group.keys():\n",
    "            _, gidx, _, time = d.split('_')\n",
    "            gidx, time = int(gidx), int(time)\n",
    "            times[gidx] = time\n",
    "            notes[gidx] = nts_group[d][:]\n",
    "\n",
    "        mask = np.zeros(NOTES_TIME_DIM)\n",
    "        for idx in times:\n",
    "            mask[idx] = 1\n",
    "\n",
    "        notes = padded_stack(notes)\n",
    "        notes = pad_missing(notes, mask)\n",
    "\n",
    "        return notes, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "2b066754-58ee-4e80-a0a0-eaf79069c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpatient_notes(pat_id):\n",
    "        nst, nts = np.empty(0), (np.empty(0), np.empty(0), np.empty(0))\n",
    "        nst_msk, nts_msk = np.zeros(1), np.zeros(NOTES_TIME_DIM)\n",
    "\n",
    "        if pat_id in nst_ids:\n",
    "            with h5py.File(notes_static_path, 'r') as f:\n",
    "                nst = f[f'pat_id_{pat_id}'][:]\n",
    "                nst_msk[0] = 1\n",
    "\n",
    "        if pat_id in nts_ids:\n",
    "            with h5py.File(notes_ts_path, 'r') as f:\n",
    "                nts, nts_msk = _format_notes_ts_group(f[f'pat_id_{pat_id}'])\n",
    "\n",
    "        return nst, nts, nst_msk, nts_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "220bf5c3-77f6-424b-afe7-76f2a4aa376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_axis(arr: np.array, fill_to: int, axis: int):\n",
    "    assert axis < arr.ndim\n",
    "\n",
    "    curr_dim = arr.shape[axis]\n",
    "    padding = [(0, 0)] * arr.ndim\n",
    "    padding[axis] = (0, fill_to-curr_dim)\n",
    "    return np.pad(arr, padding)\n",
    "\n",
    "\n",
    "def padded_stack(mat: List[np.array], fill_dims=None):\n",
    "    ndim = mat[0].ndim\n",
    "\n",
    "    if fill_dims is None:\n",
    "        fill_dims = np.max([sub.shape for sub in mat], axis=0)\n",
    "    elif ndim == 1 and type(fill_dims) == int:\n",
    "        fill_dims = [fill_dims]\n",
    "    else:\n",
    "        max_dims = np.max([sub.shape for sub in mat], axis=0)\n",
    "        fill_dims = [mdim if dim==-1 else dim for mdim, dim in zip(max_dims, fill_dims)]\n",
    "\n",
    "    padded_mats = []\n",
    "    for submat in mat:\n",
    "        padding = [(0, fill_to-dim)\n",
    "                   for dim, fill_to in zip(submat.shape, fill_dims)]\n",
    "        padded_mats.append(np.pad(submat, padding))\n",
    "\n",
    "    return np.array(padded_mats)\n",
    "\n",
    "\n",
    "def pad_missing(mat: np.array, mask: np.array):\n",
    "    new_shape = mask.shape[0:1] + mat.shape[1:]\n",
    "    full = np.zeros(new_shape)\n",
    "\n",
    "    mask_idx = 0\n",
    "    for full_idx, exists in enumerate(mask):\n",
    "        if exists:\n",
    "            full[full_idx] = mat[mask_idx]\n",
    "            mask_idx += 1\n",
    "\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeac7b7-c04a-4ba5-aca8-77e7f6c54de3",
   "metadata": {},
   "source": [
    "### Sample Get (Multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "aedfac04-f561-453c-9be7-27ac48eee4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_idx = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "29232b36-3244-4d46-a5bd-26e1eb0cf123",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_ids = indexes[item_idx]\n",
    "vit = vitals.loc[pat_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d4adc10b-77f5-4586-b907-5252bc1e1e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 150, 104)\n",
      "(4, 150)\n"
     ]
    }
   ],
   "source": [
    "vitp, vit_msk = _format_ts_batch(vit)\n",
    "print(vitp.shape)\n",
    "print(vit_msk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d2bcb53b-f714-44f1-8dc0-4049de4a2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitp = _format_ts_batch(vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f431a930-b5e2-4790-8220-a7ffccba920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(150, 150, 104), (150, 150)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pad_axis(row, TIMESERIES_DIM, 0).shape for row in vitp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "00ee0077-a26d-4fa2-96fd-53d6cfe96983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vitp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic3",
   "language": "python",
   "name": "mimic3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
