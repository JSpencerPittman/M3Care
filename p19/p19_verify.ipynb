{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P19 Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "os.chdir('..')\n",
    "from raindrop.raindrop import Raindrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = Path('./p19/data/processed_data')\n",
    "static_feat_names = np.load(PROCESSED_PATH / 'labels_demogr.npy')\n",
    "ts_feat_names = np.load(PROCESSED_PATH / 'labels_ts.npy')\n",
    "inputs = np.load(PROCESSED_PATH / 'PT_dict_list_6.npy', allow_pickle=True)\n",
    "labels = np.load(PROCESSED_PATH / 'arr_outcomes_6.npy').squeeze()\n",
    "\n",
    "ts_inputs = np.array([inp['arr'] for inp in inputs])[:, :, :, np.newaxis]\n",
    "static_inputs = np.array([inp['extended_static'] for inp in inputs])\n",
    "times = np.array([inp['time'] for inp in inputs]).squeeze()\n",
    "lengths = np.array([inp['length'] for inp in inputs])\n",
    "\n",
    "ts_inputs = torch.tensor(ts_inputs, dtype=torch.float32)\n",
    "static_inputs = torch.tensor(static_inputs, dtype=torch.float32)\n",
    "times = torch.tensor(times, dtype=torch.float32)\n",
    "lengths = torch.tensor(lengths)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_samples = ts_inputs.shape[0]\n",
    "idxs = np.arange(num_samples)\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "train_idxs, val_idxs, test_idxs = idxs[:(s1 := int(num_samples*0.8))], idxs[s1: (s2 := int(num_samples*0.9))], idxs[s2:]\n",
    "\n",
    "train_ts_inp, val_ts_inp, test_ts_inp = ts_inputs[train_idxs], ts_inputs[val_idxs], ts_inputs[test_idxs]\n",
    "train_static_inp, val_static_inp, test_static_inp = static_inputs[train_idxs], static_inputs[val_idxs], static_inputs[test_idxs]\n",
    "train_times, val_times, test_times = times[train_idxs], times[val_idxs], times[test_idxs]\n",
    "train_lengths, val_lengths, test_lengths = lengths[train_idxs], lengths[val_idxs], lengths[test_idxs]\n",
    "train_lbls, val_lbls, test_lbls = labels[train_idxs], labels[val_idxs], labels[test_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P19 Summary\n",
      "Num Samples: 38803\n",
      "\tTrain: 31042\n",
      "\tVal: 3880\n",
      "\tTest: 3881\n",
      "Classes: 1626 4.19%\n",
      "\tTrain: 1626 4.19%\n",
      "\tVal: 1299 4.18%\n",
      "\tTest: 175 4.51%\n"
     ]
    }
   ],
   "source": [
    "print(\"P19 Summary\")\n",
    "print(f\"Num Samples: {num_samples}\\n\\tTrain: {train_idxs.shape[0]}\\n\\tVal: {val_idxs.shape[0]}\\n\\tTest: {test_idxs.shape[0]}\")\n",
    "\n",
    "pos = [(int(t := labels.sum()), 100 * t / labels.shape[0])] + \\\n",
    "      [(t := int(lbls.sum()), 100 * t / lbls.shape[0]) for lbls in (train_lbls, val_lbls, test_lbls)]\n",
    "print(f\"Classes: {pos[0][0]} {pos[0][1]:.2f}%\")\n",
    "for lbl, (t, p) in zip(['Train', 'Val', 'Test'], pos):\n",
    "    print(f\"\\t{lbl}: {t} {p:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "\n",
    "class P19Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 ts_inp: Tensor,\n",
    "                 times: Tensor,\n",
    "                 lengths: Tensor,\n",
    "                 static_inp: Tensor,\n",
    "                 labels: Tensor):\n",
    "        self.ts_inp = ts_inp\n",
    "        self.times = times\n",
    "        self.lengths = lengths\n",
    "        self.static_inp = static_inp\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx: int | slice):\n",
    "        ts_inp = self.ts_inp[idx]\n",
    "\n",
    "        # Create mask\n",
    "        mask = torch.zeros(ts_inp.shape[:-1], dtype=bool)\n",
    "        if isinstance(idx, int):\n",
    "            mask[:self.lengths[idx]] = 1\n",
    "        else:\n",
    "            for idx, length in enumerate(self.lengths[idx]):\n",
    "                mask[idx, :length] = 1\n",
    "\n",
    "        return ts_inp, self.times[idx], mask, self.static_inp[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = P19Dataset(train_ts_inp, train_times, train_lengths, train_static_inp, train_lbls)\n",
    "val_ds = P19Dataset(val_ts_inp, val_times, val_lengths, val_static_inp, val_lbls)\n",
    "test_ds = P19Dataset(test_ts_inp, test_times, test_lengths, test_static_inp, test_lbls)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raindrop = Raindrop(num_sensors=34,\n",
    "                 obs_dim=1,\n",
    "                 obs_embed_dim=4,\n",
    "                 pe_emb_dim=16,\n",
    "                 timesteps=60,\n",
    "                 out_dim=128,\n",
    "                 num_layers=2,\n",
    "                 inter_sensor_attn_dim=16,\n",
    "                 temporal_attn_dim=16,\n",
    "                 prune_rate=0.5)\n",
    "\n",
    "\n",
    "\n",
    "class RaindropClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 rd_model: Raindrop,\n",
    "                 static_dim: int,\n",
    "                 static_proj_dim: int,\n",
    "                 cls_hidden_dim: int,\n",
    "                 classes: int):\n",
    "        super().__init__()\n",
    "        self.static_dim = static_dim\n",
    "        self.static_proj_dim = static_proj_dim\n",
    "        self.cls_hidden_dim = cls_hidden_dim\n",
    "        self.classes = classes\n",
    "\n",
    "        self.rd_model = rd_model\n",
    "        self.static_proj = nn.Linear(static_dim, static_proj_dim)\n",
    "\n",
    "        rd_out_dim = self.rd_model.out_dim * self.rd_model.num_sensors\n",
    "        self.cls = nn.Sequential(\n",
    "            nn.Linear(rd_out_dim + static_proj_dim, cls_hidden_dim),\n",
    "            nn.Linear(cls_hidden_dim, classes))\n",
    "\n",
    "\n",
    "    def forward(self, x_ts, times, mask, x_static):\n",
    "        ts_emb, reg_loss = self.rd_model(x_ts, times, mask)\n",
    "        ts_emb = ts_emb.view(ts_emb.shape[0], -1)\n",
    "\n",
    "        static_emb = self.static_proj(x_static)\n",
    "\n",
    "        emb = torch.concat([ts_emb, static_emb], dim=-1) \n",
    "        return F.softmax(self.cls(emb), dim=-1), reg_loss\n",
    "    \n",
    "rd_cls = RaindropClassifier(raindrop,\n",
    "                            static_dim=6,\n",
    "                            static_proj_dim=34,\n",
    "                            cls_hidden_dim=128,\n",
    "                            classes=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RaindropLoss(nn.Module):\n",
    "    def __init__(self, reg_weight: float):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.reg_weight = reg_weight\n",
    "\n",
    "    def forward(self, predictions, targets, reg_loss):\n",
    "        ce_loss = self.ce_loss(predictions, targets)\n",
    "        reg_loss *= self.reg_weight\n",
    "        return ce_loss + reg_loss\n",
    "    \n",
    "loss_fn = RaindropLoss(reg_weight=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 20\n",
    "LOSS_TRAIN_LOG_FREQ = 100\n",
    "\n",
    "\n",
    "optim = torch.optim.Adam(rd_cls.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(train_dl):\n",
    "        ts_inp, times, mask, static_inp, labels = data\n",
    "\n",
    "        optim.zero_grad()\n",
    "        outputs, reg_loss = rd_cls.forward(ts_inp, times, mask, static_inp)\n",
    "\n",
    "        loss = loss_fn(outputs, labels, reg_loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % LOSS_TRAIN_LOG_FREQ == LOSS_TRAIN_LOG_FREQ-1:\n",
    "            last_loss = running_loss / LOSS_TRAIN_LOG_FREQ\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_dl) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "CALC_INTER_SENSOR_ATTENTION\n",
      "h: torch.Size([64, 4, 60, 34, 4])\n",
      "pe: torch.Size([64, 60, 16])\n",
      "lay_idx: 0\n",
      "CALC_INTER_SENSOR_ATTENTION\n",
      "h: torch.Size([64, 4, 60, 34, 4])\n",
      "pe: torch.Size([64, 60, 16])\n",
      "lay_idx: 1\n",
      "CALC_INTER_SENSOR_ATTENTION\n",
      "h: torch.Size([64, 4, 60, 34, 4])\n",
      "pe: torch.Size([64, 60, 16])\n",
      "lay_idx: 0\n",
      "CALC_INTER_SENSOR_ATTENTION\n",
      "h: torch.Size([64, 4, 60, 34, 4])\n",
      "pe: torch.Size([64, 60, 16])\n",
      "lay_idx: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_number \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m rd_cls\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m running_vloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     15\u001b[0m rd_cls\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[59], line 12\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch_index, tb_writer)\u001b[0m\n\u001b[0;32m      9\u001b[0m outputs, reg_loss \u001b[38;5;241m=\u001b[39m rd_cls\u001b[38;5;241m.\u001b[39mforward(ts_inp, times, mask, static_inp)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels, reg_loss)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     16\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jason\\Work\\M3Care\\env\\lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    769\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    770\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/p19/p19_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = 1e6\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    rd_cls.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    rd_cls.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dl):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = rd_cls(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(rd_cls.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
